# folder-mcp Upcoming Tasks

This document tracks current and future development phases with detailed specifications.

## ğŸ“‹ Table of Contents

- [Current Development Status](#current-development-status)
- [Phase 8: Transport Foundation & Core Endpoints (Current)](#phase-8-transport-foundation--core-endpoints-current)
- [Phase 9: Advanced Endpoints & HTTP Gateway (Planned)](#phase-9-advanced-endpoints--http-gateway-planned)
- [Phase 10: Release Preparation (Planned)](#phase-10-release-preparation-planned)
- [Phase 11: UX Refinements (Planned)](#phase-11-ux-refinements-planned)
- [Phase 12: Chat Interface Integration (Future)](#phase-12-chat-interface-integration-future)
- [GitHub Project Management](#github-project-management)

---

## Current Development Status

**Current Status**: Step 33/55 - Ready for End-to-End Testing ğŸ§ª

**âœ… Recently Completed**:
- **Steps 29-32**: Transport Foundation & Complete Endpoints Implementation
  - Dual-protocol transport system (MCP + gRPC)
  - All 13 gRPC endpoints with corresponding MCP tools
  - Local Unix Domain Socket transport working
  - 277 tests passing

**â¬…ï¸ NEXT: Step 33 - End-to-End Testing**
Comprehensive testing of the complete system before adding remote access.

### Overall Timeline
- **âœ… Phases 1-7**: Foundation through Production Ready (Steps 1-28) - **COMPLETED**
- **âœ… Phase 8**: Transport Foundation & Core Endpoints (Steps 29-32) - **COMPLETED**
- **ğŸ”„ Phase 9**: System Testing & Remote Access (Steps 33-41) - **IN PROGRESS**
- **ğŸ“‹ Phase 10**: Release Preparation (Steps 42-47) - **PLANNED**
- **ğŸ“‹ Phase 11**: UX Refinements (Steps 48-51) - **PLANNED**
- **ğŸ“‹ Phase 12**: Chat Interface Integration (Steps 52-56) - **FUTURE**

---

## Phase 9: System Testing & Remote Access (Current)

**Status**: â¬…ï¸ Current - **READY FOR TESTING** ğŸ§ª

**Focus**: Comprehensive end-to-end testing followed by secure remote access implementation.

### Step 33: End-to-End System Testing
**Task**: Comprehensive testing of the complete dual-protocol system before adding remote capabilities  
**Status**: â¬…ï¸ **CURRENT** - Ready for implementation  
**Focus**: Validate all components work together correctly in real-world scenarios using `C:\ThinkingHomes\test-folder`

**Success Criteria**:
- ğŸ“‹ **Clean Server Startup**: MCP server starts without TypeScript errors, all tests pass, server listens on expected port
- ğŸ“‹ **File System Integration**: File changes trigger embedding updates within 30 seconds via filesystem watcher
- ğŸ“‹ **Claude Desktop Integration**: Complete MCP tool functionality test using structured JSON response format
- ğŸ“‹ **Real-World Document Testing**: Create/update test files (CIARA_REL_TEST.md) with realistic version release notes
- ğŸ“‹ **Cross-Protocol Validation**: Verify MCP tools can retrieve updated document information after filesystem changes
- ğŸ“‹ **Error-Free Operation**: Complete test flow executes without blocking errors (enhancement opportunities acceptable)
- ğŸ“‹ **Process Management**: Proper cleanup of running instances, port conflicts, and cache directories
- ğŸ“‹ **Log Analysis**: Claude Desktop logs show successful MCP function calls and data retrieval

**Implementation Plan**:
1. **Pre-Test Cleanup** (Steps 1-6): Kill MCP processes, clear port conflicts, delete cache, fresh terminal session
2. **Server Validation** (Step 7): Build verification, test suite execution, clean server startup
3. **Document Creation** (Step 8): Generate realistic test content with version increments and release notes
4. **Filesystem Integration** (Step 9): Verify file watcher triggers and embedding updates within 30 seconds
5. **Claude Desktop Testing** (Step 10): Structured JSON prompt for comprehensive MCP functionality validation
6. **Results Analysis** (Steps 11-12): Parse Claude responses, identify issues, plan improvements

**Test Environment**: Uses dedicated test folder with mock version files and realistic document scenarios to validate end-to-end functionality.

### Step 34: Remote Access & Cloud LLM Integration  
**Task**: Implement secure remote access for cloud LLM integration with multiple transport options  
**Status**: ğŸ“‹ **PLANNED** - Depends on Step 33 completion  
**Focus**: Enable cloud LLM access to local folder-mcp instances with multiple connectivity options

**Success Criteria**:
- ğŸ“‹ **TCP Transport**: Remote gRPC server with configurable port (50051)
- ğŸ“‹ **API Key Authentication**: Bearer token validation for remote gRPC connections
- ğŸ“‹ **TLS/mTLS Support**: Auto-generated self-signed certificates for development
- ğŸ“‹ **Cloudflare Tunnel Integration**: Zero-config remote access without port forwarding
- ğŸ“‹ **Project Subdomain Service**: Users get `username.folder-mcp.com` subdomains
- ğŸ“‹ **Let's Encrypt Integration**: Automated certificate management for custom domains
- ğŸ“‹ **Rate Limiting**: Per-key request throttling and abuse prevention
- ğŸ“‹ **Audit Logging**: Security event tracking and monitoring
- ğŸ“‹ **Certificate Management**: Auto-renewal and expiration monitoring
- ğŸ“‹ **Rate Limiting**: Per-key request throttling and abuse prevention
- ğŸ“‹ **Audit Logging**: Security event tracking and monitoring
- ğŸ“‹ **Certificate Management**: Auto-renewal and expiration monitoring

**Note**: MCP protocol will remain local-only (stdio) as Claude Desktop requires direct process communication. Remote access applies to gRPC protocol only.

**Implementation Architecture**:
- **Cloudflare Tunnel**: Primary remote access method (no port forwarding required)
  - Wildcard domain: `*.folder-mcp.com` â†’ automatic user subdomains
  - Reverse tunneling through Cloudflare's global network
  - Built-in DDoS protection and SSL certificate management
  - Comprehensive analytics dashboard for usage monitoring
- **Alternative Methods**: ngrok integration for users preferring different providers
- **Hybrid Security**: Local connections bypass auth, remote connections require API keys
- **Zero-Config UX**: `folder-mcp serve /docs --tunnel --subdomain alice` â†’ instant cloud access

**Key Technical Components**:
- **TCP Transport Layer**: Extend existing gRPC server with TCP binding
- **Certificate Strategy**: 
  - Self-signed certificates for local development and testing
  - CA-signed certificates (Let's Encrypt/Cloudflare) for production tunneling
  - Automatic certificate provisioning and renewal
- **Tunneling Integration**:
  - Cloudflare Tunnel SDK integration with automatic authentication
  - Dynamic subdomain allocation and DNS record management
  - Tunnel health monitoring and automatic reconnection
  - Fallback to alternative providers (ngrok, localtunnel)
- **Authentication System**: 
  - API key validation for all remote connections
  - Rate limiting and abuse prevention per key
  - Audit logging for security events and access patterns
  - Key lifecycle management (generation, rotation, revocation)

**Cloud LLM Integration Benefits**:
- **Zero Network Configuration**: No router setup, firewall rules, or port forwarding
- **Enterprise-Grade Security**: Cloudflare's DDoS protection and WAF
- **Global Performance**: Cloudflare's edge network optimizes connection speed
- **User-Friendly URLs**: `https://alice.folder-mcp.com` instead of `https://random-ngrok-id.ngrok.io`
- **SSL/TLS Automatic**: Cloudflare provides and manages SSL certificates
- **Analytics & Monitoring**: Built-in request analytics and performance monitoring

**Key Deliverables**:
- TCP transport with configurable binding and port settings
- Cloudflare Tunnel integration with automatic subdomain allocation
- TLS/mTLS certificate management with automatic renewal
- Remote authentication system with comprehensive security features
- Subdomain service for user-friendly cloud access
- Documentation for cloud LLM integration workflows
- CLI commands for tunnel management and remote access setup

---

## Phase 9: Advanced Endpoints & HTTP Gateway (Planned)

### Step 35: HTTP Gateway Implementation
**Task**: Implement REST/JSON gateway for gRPC services with comprehensive authentication  
**Success Criteria**:
- ğŸ“‹ HTTP server on configurable port (default 8080)
- ğŸ“‹ REST endpoints with /v1 prefix matching specification
- ğŸ“‹ JSON request/response translation to/from gRPC (not MCP - remains stdio only)
- ğŸ“‹ Proper HTTP status codes and error handling
- ğŸ“‹ CORS support for web clients
- ğŸ“‹ Request validation and sanitization

### Step 36: Summarization Endpoints & Tools
**Task**: Implement advanced summarization features for both gRPC and HTTP protocols  
**Success Criteria**:
- ğŸ“‹ Enhanced GetDocSummary with multiple modes (brief/detailed/technical)
- ğŸ“‹ BatchDocSummary with intelligent batching and progress tracking
- ğŸ“‹ Summary caching and incremental updates
- ğŸ“‹ Custom summarization templates and styles
- ğŸ“‹ Multi-language summarization support
- ğŸ“‹ Integration with HTTP gateway

### Step 37: Specialized Query Enhancements
**Task**: Enhance table querying and system monitoring capabilities  
**Success Criteria**:
- ğŸ“‹ Advanced TableQuery with SQL-like syntax support
- ğŸ“‹ Cross-document table analysis and joining
- ğŸ“‹ Enhanced IngestStatus with real-time progress tracking
- ğŸ“‹ Batch refresh operations with dependency resolution
- ğŸ“‹ Performance analytics and optimization suggestions
- ğŸ“‹ Integration with HTTP gateway

### Step 38: Advanced Search Features
**Task**: Enhance search capabilities with advanced filtering and ranking  
**Success Criteria**:
- ğŸ“‹ Complex metadata filtering (AND/OR operations)
- ğŸ“‹ Date range queries with RFC3339 timestamp support
- ğŸ“‹ Author and document type filtering
- ğŸ“‹ Search result ranking and relevance scoring
- ğŸ“‹ Search history and saved queries
- ğŸ“‹ Query performance optimization

### Step 39: Batch Operations & Streaming
**Task**: Implement efficient batch processing and streaming  
**Success Criteria**:
- ğŸ“‹ Streaming responses for large result sets
- ğŸ“‹ Batch embedding generation for multiple documents
- ğŸ“‹ Progress tracking for long-running operations
- ğŸ“‹ Cancellation support for batch operations
- ğŸ“‹ Memory-efficient processing for large files
- ğŸ“‹ Rate limiting and throttling

### Step 40: Security & Authentication Enhancement
**Task**: Implement comprehensive security features for remote access  
**Success Criteria**:
- ğŸ“‹ TLS/mTLS certificate generation and management for remote connections
- ğŸ“‹ Enhanced API key lifecycle management (generate, rotate, revoke)
- ğŸ“‹ Security audit logging with authentication events
- ğŸ“‹ Rate limiting and DDoS protection per API key
- ğŸ“‹ Access control and permission system
- ğŸ“‹ Secure key storage and retrieval

### Step 41: Integration Testing & Validation
**Task**: Comprehensive testing of transport and endpoint system  
**Success Criteria**:
- ğŸ“‹ gRPC client/server integration tests
- ğŸ“‹ HTTP gateway API testing
- ğŸ“‹ Multi-transport connection testing
- ğŸ“‹ Load testing for all endpoints
- ğŸ“‹ Error handling and recovery testing
- ğŸ“‹ Performance benchmarking and optimization

---

## Phase 10: Release Preparation (Planned)
### Step 42: Hugging Face Hub Integration for Model Metadata
**Task**: Enhance Ollama model information with Hugging Face Hub metadata  
**Success Criteria**:
- ğŸ“‹ Fetch model metadata from Hugging Face Hub API
- ğŸ“‹ Extract language support information from model cards
- ğŸ“‹ Augment Ollama model list with HF metadata
- ğŸ“‹ Implement intelligent language-based model filtering
- ğŸ“‹ Cache HF metadata with 24-hour expiry
- ğŸ“‹ Handle API rate limits and offline scenarios gracefully
- ğŸ“‹ Provide rich model selection with language capabilities

**Implementation Approach**:
1. **Model ID Mapping**: Map Ollama model names to Hugging Face model IDs
2. **Batch API Requests**: Fetch multiple model metadata in parallel with rate limiting
3. **Language Detection**: Parse model cards and tags for language information
4. **Confidence Scoring**: Rate quality of language support data
5. **Caching Strategy**: Store combined Ollama + HF data in unified cache
6. **Fallback Logic**: Graceful degradation when HF API unavailable

**API Integration Details**:
```
GET https://huggingface.co/api/models/{model_id}
â†’ Returns: model card, tags, pipeline info, language data

Example Response:
{
  "id": "sentence-transformers/all-MiniLM-L6-v2",
  "pipeline_tag": "sentence-similarity", 
  "tags": ["sentence-transformers", "pytorch", "safetensors"],
  "languages": ["en"],
  "license": "apache-2.0",
  "downloads": 50000000,
  "lastModified": "2023-11-20T10:30:00.000Z"
}
```

**Enhanced User Experience**:
- Show language support when listing models: `mxbai-embed-large (100+ languages)`
- Filter models by language: `--language zh,en` 
- Smart defaults: Auto-select best multilingual model for diverse document sets
- Confidence indicators: High/Medium/Low confidence for language support data

### Step 43: Performance Optimization
**Task**: Optimize for production deployment  
**Success Criteria**:
- ğŸ“‹ Connection pooling and resource management
- ğŸ“‹ Caching strategies for frequently accessed data
- ğŸ“‹ Memory optimization for large document sets
- ğŸ“‹ Database indexing and query optimization
- ğŸ“‹ Concurrent request handling optimization
- ğŸ“‹ Network protocol optimization

### Step 44: Test Suite Integration
**Task**: Extend existing test suite for new transport system  
**Success Criteria**:
- ğŸ“‹ Add gRPC transport testing to existing test infrastructure
- ğŸ“‹ HTTP gateway endpoint testing
- ğŸ“‹ Multi-protocol integration testing
- ğŸ“‹ Performance benchmarking for all endpoints
- ğŸ“‹ Security and authentication testing
- ğŸ“‹ Load testing and stress testing

**Note**: Leverages existing comprehensive test system (238 tests, 99.6% pass rate) by extending with transport-specific tests while maintaining current test infrastructure and patterns.

### Step 45: Documentation & API Reference
**Task**: Complete comprehensive documentation  
**Success Criteria**:
- ğŸ“‹ API documentation with OpenAPI/Swagger spec
- ğŸ“‹ gRPC service documentation
- ğŸ“‹ Transport configuration guide
- ğŸ“‹ Deployment and scaling guide
- ğŸ“‹ Security configuration documentation
- ğŸ“‹ Troubleshooting and debugging guide

### Step 46: Containerization & Deployment
**Task**: Prepare for containerized deployment  
**Success Criteria**:
- ğŸ“‹ Docker containerization with multi-stage builds
- ğŸ“‹ Docker Compose for local development
- ğŸ“‹ Kubernetes deployment manifests
- ğŸ“‹ Health checks and readiness probes
- ğŸ“‹ Environment variable configuration
- ğŸ“‹ Horizontal scaling support

### Step 47: Release 1.0.0
**Task**: Publish production-ready release  
**Success Criteria**:
- ğŸ“‹ Publish to npm registry with all transport options
- ğŸ“‹ GitHub release with binary distributions
- ğŸ“‹ Docker Hub container publication
- ğŸ“‹ Documentation website deployment
- ğŸ“‹ Community announcement and promotion
- ğŸ“‹ User feedback collection system

---

## Phase 11: UX Refinements (Planned)

**NOTE**: These remaining UX steps were moved from the original Phase 8 to allow immediate focus on transport and endpoints implementation.

### Step 48: CLI Parameter Override System
**Task**: Allow CLI parameters to override runtime defaults  
**Success Criteria**:
- ğŸ“‹ Parse all CLI parameters into runtime config
- ğŸ“‹ Override only specified parameters
- ğŸ“‹ Detect changes in embedding config (model, chunk_size, overlap)
- ğŸ“‹ Trigger re-indexing if embedding params changed
- ğŸ“‹ Show warning: "Config changed, re-indexing required"
- ğŸ“‹ Update cached runtime with successful execution
- ğŸ“‹ Update --help for the tool

### Step 49: Configuration Wizard Implementation
**Task**: Create --wizard interactive configuration generator  
**Success Criteria**:
- ğŸ“‹ Launch with folder-mcp --wizard
- ğŸ“‹ Load current runtime config as defaults
- ğŸ“‹ Ask questions with current values pre-filled
- ğŸ“‹ Generate CLI command string from answers
- ğŸ“‹ Display command and ask: "Run this command? Y/n"
- ğŸ“‹ Execute command or copy to clipboard

### Step 50: System Detection Integration
**Task**: Auto-detect system capabilities for smart defaults  
**Success Criteria**:
- ğŸ“‹ Detect CPU, RAM, GPU on first run
- ğŸ“‹ Update runtime config with optimal settings
- ğŸ“‹ Select best model based on system tier
- ğŸ“‹ Integrate with Ollama for model availability
- ğŸ“‹ Run only when cache missing or --detect flag
- ğŸ“‹ Show detected specs in --show-config output

### Step 51: Full-Screen UI Implementation
**Task**: Create main operation interface  
**Success Criteria**:
- ğŸ“‹ Launch after configuration is validated
- ğŸ“‹ Display real-time indexing progress
- ğŸ“‹ Show file processing statistics
- ğŸ“‹ Monitor memory and performance
- ğŸ“‹ Include error log panel
- ğŸ“‹ Add keyboard navigation

---

## Phase 12: Chat Interface Integration (Future)

### Step 52: Chat Configuration Wizard
**Task**: Create interactive wizard for chat setup using new transport layer  
**Success Criteria**:
- ğŸ“‹ Launch with `folder-mcp chat --setup`
- ğŸ“‹ Auto-detect available transport options (local gRPC, remote gRPC, HTTP)
- ğŸ“‹ Cloud vs Local GPU selection interface
- ğŸ“‹ Provider selection with clear descriptions
- ğŸ“‹ API key validation with test calls
- ğŸ“‹ Ollama model detection and recommendation
- ğŸ“‹ Transport selection and configuration
- ğŸ“‹ Save chat configuration leveraging new config system

**Chat Configuration Flow leveraging gRPC Transport**:
```
folder-mcp chat <folder> (first time)
â†’ Chat Setup Wizard
   â”œâ”€â”€ Transport Selection:
   â”‚   â”œâ”€â”€ Local gRPC (unix socket) - Best performance
   â”‚   â”œâ”€â”€ Remote gRPC (TCP) - Distributed setup
   â”‚   â””â”€â”€ HTTP Gateway - Web compatibility
   â”‚
   â”œâ”€â”€ Choose: Cloud or Local GPU?
   â”‚
   â”œâ”€ Cloud Path:
   â”‚  â”œâ”€â”€ Select Provider:
   â”‚  â”‚   â”œâ”€â”€ OpenAI (GPT-4, GPT-3.5-turbo)
   â”‚  â”‚   â”œâ”€â”€ Anthropic (Claude 3.5 Sonnet, Claude 3 Haiku)
   â”‚  â”‚   â”œâ”€â”€ Google (Gemini Pro, Gemini Flash)
   â”‚  â”‚   â””â”€â”€ Azure OpenAI
   â”‚  â”œâ”€â”€ Enter API Key â†’ Validate â†’ Test call via transport
   â”‚  â”œâ”€â”€ Auto-select best model for provider
   â”‚  â””â”€â”€ Save config â†’ Launch chat
   â”‚
   â””â”€ Local GPU Path:
      â”œâ”€â”€ Check Ollama installation
      â”œâ”€â”€ Scan available models via transport
      â”œâ”€â”€ Show model list with embedding compatibility
      â”œâ”€â”€ Auto-recommend based on system specs
      â”œâ”€â”€ Download model if needed (with progress)
      â””â”€â”€ Save config â†’ Launch chat
```

### Step 53: Cloud Provider Integration
**Task**: Implement cloud LLM provider APIs with transport layer  
**Success Criteria**:
- ğŸ“‹ OpenAI API integration with streaming responses
- ğŸ“‹ Anthropic Claude API with proper formatting
- ğŸ“‹ Google Gemini API integration
- ğŸ“‹ Azure OpenAI support
- ğŸ“‹ Transport-agnostic LLM client interface
- ğŸ“‹ API routing through gRPC or HTTP transport
- ğŸ“‹ Rate limiting and quota management via transport

### Step 54: Local LLM Integration
**Task**: Implement Ollama local LLM integration via transport  
**Success Criteria**:
- ğŸ“‹ Ollama service detection and health checks
- ğŸ“‹ Model listing with installation status via transport
- ğŸ“‹ Automatic model downloading with progress
- ğŸ“‹ System resource monitoring during chat
- ğŸ“‹ Model recommendation based on RAM/VRAM
- ğŸ“‹ Transport-optimized local inference
- ğŸ“‹ Performance optimization for gRPC streaming

### Step 55: Interactive Chat Interface
**Task**: Create the main chat experience using transport endpoints  
**Success Criteria**:
- ğŸ“‹ CLI-based chat interface with rich formatting
- ğŸ“‹ Context-aware responses using SearchDocs/SearchChunks endpoints
- ğŸ“‹ Real-time document retrieval via transport
- ğŸ“‹ Source document attribution using GetDocMetadata
- ğŸ“‹ Streaming responses via gRPC or HTTP
- ğŸ“‹ Commands: `/help`, `/sources`, `/clear`, `/export`
- ğŸ“‹ Integration with BatchDocSummary for context preparation
- ğŸ“‹ Transport performance monitoring during chat

**Chat Interface Flow leveraging Transport Endpoints**:
```
folder-mcp chat <folder>
â†’ Load chat config â†’ Connect to transport â†’ Start chat session

Chat Interface using gRPC/HTTP endpoints:
â”Œâ”€ Chat with Documents in: ./my-folder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“ Sources: 47 documents indexed (via IngestStatus)       â”‚
â”‚ ğŸ¤– Model: Claude 3.5 Sonnet (Cloud) / llama3.1:8b (Local)â”‚
â”‚ ğŸ”— Transport: gRPC/Unix Socket (high performance)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ You: What are the main topics in my research papers?      â”‚
â”‚                                                            â”‚
â”‚ ğŸ¤– Assistant: Based on your documents, I found 3 main    â”‚
â”‚ research topics: (via SearchDocs + BatchDocSummary)       â”‚
â”‚                                                            â”‚
â”‚ 1. **Machine Learning Applications** (12 papers)          â”‚
â”‚    Sources: ml-survey.pdf, neural-networks.docx           â”‚
â”‚                                                            â”‚
â”‚ 2. **Data Analysis Methods** (8 papers)                   â”‚
â”‚    Sources: statistics-overview.pdf, data-mining.docx     â”‚
â”‚                                                            â”‚
â”‚ 3. **Software Engineering** (5 papers)                    â”‚
â”‚    Sources: agile-methods.pdf, testing-strategies.docx    â”‚
â”‚                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Type your message... (/help for commands)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 56: Chat History & Export
**Task**: Implement chat session management with transport integration  
**Success Criteria**:
- ğŸ“‹ Save chat sessions with document references
- ğŸ“‹ Session naming and organization
- ğŸ“‹ Resume previous chat sessions with transport reconnection
- ğŸ“‹ Export options: Markdown, JSON, TXT with source links
- ğŸ“‹ Search chat history using existing search infrastructure
- ğŸ“‹ Delete old sessions with cleanup
- ğŸ“‹ Session sharing with transport endpoint references
- ğŸ“‹ Privacy controls for sensitive conversations

---

## GitHub Project Management

This section provides guidance for setting up GitHub Issues to track development progress.

### Quick Setup Instructions

1. **Go to your GitHub repository**: https://github.com/okets/folder-mcp
2. **Click "Issues" tab** â†’ **"New Issue"**
3. **Create issues for each step** using the templates below
4. **Set labels and milestones** as indicated

### GitHub Milestones

Create these milestones in GitHub (Issues â†’ Milestones â†’ New milestone):

1. **Phase 8 - Transport & Core Endpoints** (Due: Current - PRIORITIZED) ğŸš€
2. **Phase 9 - Advanced Endpoints & HTTP Gateway** (Due: TBD)
3. **Phase 10 - Release Preparation** (Due: TBD)
4. **Phase 11 - UX Refinements** (Due: TBD)
5. **Phase 12 - Chat Interface Integration** (Due: TBD)

### GitHub Labels

Create these labels for categorization:

- `enhancement` (blue), `grpc` (steel blue), `transport` (coral), `http-gateway` (lavender)
- `endpoints` (mint), `security` (crimson), `monitoring` (forest green)
- `config` (lime), `cli` (green), `performance` (maroon), `testing` (navy)
- `documentation` (silver), `packaging` (teal), `release` (gold)

### Issue Template

For each step in the roadmap, create a GitHub issue with:

**Title**: `[Step X] Brief Description` (e.g., "[Step 34] Transport Layer Foundation")

**Labels**: `enhancement` + relevant category (e.g., `transport`)

**Milestone**: Appropriate phase (e.g., "Phase 8 - Transport & Core Endpoints")

**Description**:
```
### Description
[Copy the task description from the roadmap]

### Success Criteria
[Copy the success criteria checklist from the roadmap]

### Status
- ğŸ”„ **IN PROGRESS** / **TODO**
```

### Benefits

- **Clear progress tracking**: See exactly what's done vs. what's planned
- **Contributor onboarding**: New developers can see the roadmap and pick tasks
- **User expectations**: Users understand current capabilities vs. future features  
- **Development focus**: Prioritized task list for systematic development
- **Community engagement**: Users can vote on features and contribute to specific areas
